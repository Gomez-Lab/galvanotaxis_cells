{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BASE MODEL BOXPLOT\n",
    "\n",
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "\n",
    "err_train = []\n",
    "err_val = []\n",
    "err_test = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir0'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        for i in range(50):\n",
    "            cell_errors = train[train['track']==track]['pred_error{}'.format(i)]\n",
    "            err_train.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors))))) \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir0'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = val[val['track']==track]['pred_error{}'.format(i)]\n",
    "            err_val.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir0'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_train, err_val, err_test]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM', fontsize=18)\n",
    "ax.set_xlabel('Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.7, patch_artist=True)\n",
    "plt.xticks(np.arange(1,4), labels=['Train', 'Validation', 'Test'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "color = 'lightblue'\n",
    "for patch in boxes['boxes']:\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [median_label,mean_label],\n",
    "    ['Median','Mean'],\n",
    "    bbox_to_anchor=(.9,1.0), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/cncc_trainvaltest_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err_train, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train), IQR, statistics.mean(err_train), statistics.stdev(err_train)))\n",
    "\n",
    "Q1 = np.percentile(err_val, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val), IQR, statistics.mean(err_val), statistics.stdev(err_val)))\n",
    "     \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#NAIVE BOXPLOT\n",
    "\n",
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_naive.csv')\n",
    "\n",
    "err_lstm = []\n",
    "err_naive = []\n",
    "err_lin = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    lstm = df[(df['set']==2) & (df['pred_dir0'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = lstm[lstm['track']==track]['pred_error{}'.format(i)]\n",
    "            err_lstm.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))  \n",
    "\n",
    "    naive = df2[(df2['set']==2) & (df2['pred_naive'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = naive[naive['track']==track]['naive_error']\n",
    "        err_naive.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "        \n",
    "    lin = df2[(df2['set']==2) & (df2['pred_lin'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = lin[lin['track']==track]['lin_error']\n",
    "        err_lin.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_lstm, err_naive, err_lin]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('LSTM and Naive Test Set Errors', fontsize=18)\n",
    "ax.set_xlabel('Model', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.7, patch_artist=True)\n",
    "plt.xticks(np.arange(1,4), labels=['LSTM', 'Constant\\nDirectedness', 'Linear\\nPredictor'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "base_color = 'lightblue'\n",
    "const_color='lightpink'\n",
    "linear_color = 'orchid'\n",
    "colors = [base_color,const_color,linear_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [median_label,mean_label],\n",
    "    ['Median','Mean'],\n",
    "    fancybox=True, shadow=True, fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/cncc_naive_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err_lstm, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_lstm, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('LSTM Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_lstm), IQR, statistics.mean(err_lstm), statistics.stdev(err_lstm)))\n",
    "\n",
    "Q1 = np.percentile(err_naive, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_naive, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('One-Step Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_naive), IQR, statistics.mean(err_naive), statistics.stdev(err_naive)))\n",
    "     \n",
    "Q1 = np.percentile(err_lin, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_lin, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Two-Step Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_lin), IQR, statistics.mean(err_lin), statistics.stdev(err_lin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INTERPOLATION BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model\n",
    "df_inter=pd.read_csv('data/cncc_no30_predictions.csv') #load interpolation model - trained w/o 30mV/mm\n",
    "\n",
    "#errors on the full test set\n",
    "err_base_all = []\n",
    "err_inter_all = []\n",
    "#errors on 30mV/mm test instances\n",
    "err_base_30 = []\n",
    "err_inter_30 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # Get errors from base model\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base_all.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            if ef==30:\n",
    "                err_base_30.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "                \n",
    "    # Get errors from interpolation model\n",
    "    test = df_inter[(df_inter['set']==2) & (df_inter['pred_dir0'].notna())& (df_inter['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_inter_all.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            if ef==30:\n",
    "                err_inter_30.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base_all,err_inter_all,err_base_30,err_inter_30]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Interpolation Model Error', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, positions=[0.8,1.2,1.8,2.2], widths=0.35, patch_artist=True)\n",
    "plt.xticks([1,2], labels=['Full Test Set', '30mV/mm Instances'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "inter_color = 'lightgreen'\n",
    "colors = [base_color, inter_color, base_color, inter_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "inter_label, = ax.plot([],'s',color=inter_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [base_label,inter_label,median_label,mean_label],\n",
    "    ['Base Model','Interpolation Model','Median','Mean'],\n",
    "    bbox_to_anchor=(0.85,1), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/cncc_interpolation_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRAPOLATION BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model\n",
    "df_inter=pd.read_csv('data/cncc_no200_predictions.csv') #load interpolation model - trained w/o 200mV/mm\n",
    "\n",
    "#errors on the full test set\n",
    "err_base_all = []\n",
    "err_inter_all = []\n",
    "#errors on 30mV/mm test instances\n",
    "err_base_200 = []\n",
    "err_inter_200 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # Get errors from base model\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base_all.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            if ef==200:\n",
    "                err_base_200.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "                \n",
    "    # Get errors from interpolation model\n",
    "    test = df_inter[(df_inter['set']==2) & (df_inter['pred_dir0'].notna())& (df_inter['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_inter_all.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            if ef==200:\n",
    "                err_inter_200.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base_all,err_inter_all,err_base_200,err_inter_200]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Extrapolation Model Error', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, positions=[0.8,1.2,1.8,2.2], widths=0.35, patch_artist=True)\n",
    "plt.xticks([1,2], labels=['Full Test Set', '200mV/mm Instances'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "ext_color = 'aquamarine'\n",
    "colors = [base_color, ext_color, base_color, ext_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "ext_label, = ax.plot([],'s',color=ext_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [base_label,ext_label,median_label,mean_label],\n",
    "    ['Base Model','Extrapolation Model','Median','Mean'],\n",
    "    bbox_to_anchor=(0.85,1), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/cncc_extrapolation_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVERSAL BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_rev=pd.read_csv('data/reversal_predictions.csv') #load reversal model data\n",
    "df_trans=pd.read_csv('data/reversal_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_rev = []\n",
    "err_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from reversal tests\n",
    "\n",
    "#base model on reversal\n",
    "\n",
    "#reversal model\n",
    "test = df_rev[(df_rev['pred_dir0'].notna())]\n",
    "for track in test['track'].unique():\n",
    "    for i in range(50):\n",
    "        cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "        err_rev.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "#transfer learning model\n",
    "test = df_trans[(df_trans['pred_dir0'].notna())]\n",
    "for track in test['track'].unique():\n",
    "    for i in range(50):\n",
    "        cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "        err_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base,err_rev,err_trans]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Polarity Reversal Prediction Errors', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "plt.xticks([1,2,3], labels=['CNCC', 'Reversal', 'Reversal'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "rev_color = 'orchid'\n",
    "trans_color = 'darkslateblue'\n",
    "colors = [base_color, rev_color, trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "rev_label, = ax.plot([],'s',color=rev_color)\n",
    "trans_label, = ax.plot([],'s',color=trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "lgd=ax.legend(\n",
    "    [base_label,rev_label,trans_label,median_label,mean_label],\n",
    "    ['Base Model','Reversal Model','Base to Reversal Transfer','Median','Mean'],\n",
    "    bbox_to_anchor=(0.9,0.99), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/reversal_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KERATOCYTE BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_ker=pd.read_csv('data/keratocyte_predictions.csv') #load keratocyte model data\n",
    "df_trans=pd.read_csv('data/keratocyte_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_ker = []\n",
    "err_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratocyte models\n",
    "for ef in df_ker['ef'].unique():\n",
    "    #keratocyte model\n",
    "    test = df_ker[(df_ker['pred_dir0'].notna())& (df_ker['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_ker.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_trans[(df_trans['pred_dir0'].notna())& (df_trans['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base,err_ker,err_trans]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Keratocyte Prediction Errors', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "plt.xticks([1,2,3], labels=['CNCC', 'Keratocyte', 'Keratocyte'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "ker_color = 'lime'\n",
    "trans_color = 'springgreen'\n",
    "colors = [base_color, ker_color, trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "ker_label, = ax.plot([],'s',color=ker_color)\n",
    "trans_label, = ax.plot([],'s',color=trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [base_label,ker_label,trans_label,median_label,mean_label],\n",
    "    ['Base Model','Keratocyte Model','CNCC to Keratocyte Transfer','Median','Mean'],\n",
    "    bbox_to_anchor=(0.6,1.03), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/keratocyte_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KERATINOCYTE SET 1 BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_ker=pd.read_csv('data/NHK0001_predictions.csv') #load keratocyte model data\n",
    "df_trans=pd.read_csv('data/NHK0001_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_ker = []\n",
    "err_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratinocyte models\n",
    "#keratinocyte model\n",
    "test = df_ker[(df_ker['pred_dir0'].notna())]\n",
    "for track in test['track'].unique():\n",
    "    for i in range(50):\n",
    "        cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "        err_ker.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "#transfer learning model\n",
    "test = df_trans[(df_trans['pred_dir0'].notna())]\n",
    "for track in test['track'].unique():\n",
    "    for i in range(50):\n",
    "        cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "        err_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "\n",
    "print(len(err_ker))        \n",
    "print(len(err_trans))    \n",
    "\n",
    "errors = [err_base,err_ker,err_trans]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Keratinocyte 1min Prediction Errors', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "plt.xticks([1,2,3], labels=['CNCC', 'Keratinocyte', 'Keratinocyte'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "ker_color = 'olivedrab'\n",
    "trans_color = 'yellowgreen'\n",
    "colors = [base_color, ker_color, trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "ker_label, = ax.plot([],'s',color=ker_color)\n",
    "trans_label, = ax.plot([],'s',color=trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "ax.legend(\n",
    "    [base_label,ker_label,trans_label,median_label,mean_label],\n",
    "    ['Base Model','Keratinocyte 1 Model','CNCC to Keratinocyte 1 Transfer','Median','Mean'],\n",
    "    bbox_to_anchor=(0.65,1), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/NHK0001_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KERATINOCYTE SET 2 BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_ker=pd.read_csv('data/NHK0002_predictions.csv') #load keratocyte model data\n",
    "df_trans=pd.read_csv('data/NHK0002_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_ker = []\n",
    "err_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratinocyte models\n",
    "for ef in df_ker['ef'].unique():\n",
    "    #keratinocyte model\n",
    "    test = df_ker[(df_ker['pred_dir0'].notna())& (df_ker['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_ker.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_trans[(df_trans['pred_dir0'].notna())& (df_trans['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base,err_ker,err_trans]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Keratinocyte 1min Set 2 Prediction Errors', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "plt.xticks([1,2,3], labels=['CNCC', 'Keratinocyte', 'Keratinocyte'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "ker_color = 'crimson'\n",
    "trans_color = 'palevioletred'\n",
    "colors = [base_color, ker_color, trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "ker_label, = ax.plot([],'s',color=ker_color)\n",
    "trans_label, = ax.plot([],'s',color=trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "lgd=ax.legend(\n",
    "    [base_label,ker_label,trans_label,median_label,mean_label],\n",
    "    ['Base Model','Keratinocyte Model 2','CNCC to Keratinocyte 2 Transfer','Median','Mean'],\n",
    "    bbox_to_anchor=(0.65,1), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/NHK0002_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KERATINOCYTE SET 3 BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_ker=pd.read_csv('data/NHK0802-YL112208_predictions.csv') #load keratocyte model data\n",
    "df_trans=pd.read_csv('data/NHK0802-YL112208_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_ker = []\n",
    "err_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratinocyte models\n",
    "for ef in df_ker['ef'].unique():\n",
    "    #keratinocyte model\n",
    "    test = df_ker[(df_ker['pred_dir0'].notna())& (df_ker['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_ker.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_trans[(df_trans['pred_dir0'].notna())& (df_trans['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base,err_ker,err_trans]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Keratinocyte 10min Prediction Errors', fontsize=18)\n",
    "ax.set_xlabel('Test Set', fontsize=16)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=16)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "plt.xticks([1,2,3], labels=['CNCC', 'Keratinocyte', 'Keratinocyte'], fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "ker_color = 'rebeccapurple'\n",
    "trans_color = 'mediumpurple'\n",
    "colors = [base_color, ker_color, trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color)\n",
    "ker_label, = ax.plot([],'s',color=ker_color)\n",
    "trans_label, = ax.plot([],'s',color=trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "lgd=ax.legend(\n",
    "    [base_label,ker_label,trans_label,median_label,mean_label],\n",
    "    ['Base Model','Keratinocyte Model 3','CNCC to Keratinocyte 3 Transfer','Median','Mean'],\n",
    "    bbox_to_anchor=(0.65,1), fancybox=True, shadow=True, loc='upper left', fontsize=14)\n",
    "    \n",
    "plt.savefig('figures/NHK0802-YL112208_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL OTHER CELL TYPES BOXPLOT\n",
    "\n",
    "df_base=pd.read_csv('data/cncc_predictions.csv') #load base model data \n",
    "df_keratocyte=pd.read_csv('data/keratocyte_predictions.csv') #load keratocyte model data\n",
    "df_keratocyte_trans=pd.read_csv('data/keratocyte_transfer_predictions.csv') #load transfer learning data\n",
    "df_keratinocyte1=pd.read_csv('data/NHK0001_predictions.csv') #load keratinocyte model 1 data\n",
    "df_keratinocyte1_trans=pd.read_csv('data/NHK0001_transfer_predictions.csv') #load transfer learning data\n",
    "df_keratinocyte10=pd.read_csv('data/NHK0802-YL112208_predictions.csv') #load keratinocyte 10 model data\n",
    "df_keratinocyte10_trans=pd.read_csv('data/NHK0802-YL112208_transfer_predictions.csv') #load transfer learning data\n",
    "\n",
    "#errors on the respective test sets\n",
    "err_base = []\n",
    "err_keratocyte = []\n",
    "err_keratocyte_trans = []\n",
    "err_keratinocyte1 = []\n",
    "err_keratinocyte1_trans = []\n",
    "err_keratinocyte10 = []\n",
    "err_keratinocyte10_trans = []\n",
    "\n",
    "# Get errors from base model on benchmark data\n",
    "for ef in df_base['ef'].unique():\n",
    "    test = df_base[(df_base['set']==2) & (df_base['pred_dir0'].notna())& (df_base['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_base.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratocyte models\n",
    "for ef in df_keratocyte['ef'].unique():\n",
    "    #keratocyte model\n",
    "    test = df_keratocyte[(df_keratocyte['pred_dir0'].notna())& (df_keratocyte['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratocyte.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_keratocyte_trans[(df_keratocyte_trans['pred_dir0'].notna())& (df_keratocyte_trans['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratocyte_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratinocyte 1min models\n",
    "for ef in df_keratinocyte1['ef'].unique():\n",
    "    #keratinocyte model\n",
    "    test = df_keratinocyte1[(df_keratinocyte1['pred_dir0'].notna())]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratinocyte1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_keratinocyte1_trans[(df_keratinocyte1_trans['pred_dir0'].notna())]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratinocyte1_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "# Get errors from keratinocyte 10min models\n",
    "for ef in df_keratinocyte10['ef'].unique():\n",
    "    #keratinocyte model\n",
    "    test = df_keratinocyte10[(df_keratinocyte10['pred_dir0'].notna())& (df_keratinocyte10['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratinocyte10.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "            \n",
    "    #transfer learning model\n",
    "    test = df_keratinocyte10_trans[(df_keratinocyte10_trans['pred_dir0'].notna())& (df_keratinocyte10_trans['ef']==ef)]\n",
    "    for track in test['track'].unique():\n",
    "        for i in range(50):\n",
    "            cell_errors = test[test['track']==track]['pred_error{}'.format(i)]\n",
    "            err_keratinocyte10_trans.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(len(cell_errors)))))\n",
    "    \n",
    "errors = [err_base,err_keratocyte,err_keratocyte_trans,err_keratinocyte1,err_keratinocyte1_trans,\n",
    "         err_keratinocyte10, err_keratinocyte10_trans]\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "ax.set_title('Prediction Errors on Target Cell Types', fontsize=32)\n",
    "ax.set_xlabel('Test Set', fontsize=24)\n",
    "ax.set_ylabel('Cell-Level RMSE', fontsize=24)\n",
    "#fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "boxes = ax.boxplot(errors, showmeans=True, showfliers=False, widths=0.4, patch_artist=True)\n",
    "#plt.xticks(range(1,8), labels=['CNCC', 'Keratocyte', 'Keratocyte', 'Keratinocyte 1min', 'Keratinocyte 1min',\n",
    "                           #'Keratinocyte 10min', 'Keratinocyte 10min'], fontsize=16)\n",
    "plt.xticks([1,2.5,4.5,6.5], labels=['CNCC', 'Keratocyte', 'Keratinocyte 1min', 'Keratinocyte 10min'], fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#colors\n",
    "base_color = 'lightblue'\n",
    "keratocyte_color = 'orchid'#'lime'\n",
    "keratocyte_trans_color = 'darkslateblue'#'springgreen'\n",
    "keratinocyte1_color = 'orchid'#'crimson'\n",
    "keratinocyte1_trans_color = 'darkslateblue'#'palevioletred'\n",
    "keratinocyte10_color = 'orchid'#'rebeccapurple'\n",
    "keratinocyte10_trans_color = 'darkslateblue'#'mediumpurple'\n",
    "colors = [base_color, keratocyte_color, keratocyte_trans_color, keratinocyte1_color, keratinocyte1_trans_color,\n",
    "         keratinocyte10_color, keratinocyte10_trans_color]\n",
    "for patch, color in zip(boxes['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "#legend information\n",
    "base_label, = ax.plot([],'s',color=base_color,markersize=25)\n",
    "keratocyte_label, = ax.plot([],'s',color=keratocyte_color,markersize=25)\n",
    "keratocyte_trans_label, = ax.plot([],'s',color=keratocyte_trans_color,markersize=25)\n",
    "keratinocyte1_label, = ax.plot([],'s',color=keratinocyte1_color)\n",
    "keratinocyte1_trans_label, = ax.plot([],'s',color=keratinocyte1_trans_color)\n",
    "keratinocyte10_label, = ax.plot([],'s',color=keratinocyte10_color)\n",
    "keratinocyte10_trans_label, = ax.plot([],'s',color=keratinocyte10_trans_color)\n",
    "median_label, = ax.plot([],color='orange')\n",
    "mean_label, = ax.plot([],'^',color='green')\n",
    "lgd = ax.legend(\n",
    "    [base_label, keratocyte_label, keratocyte_trans_label, median_label, mean_label],\n",
    "    ['Base Model','No Transfer Learning','Transfer Learning with CNCC','Median','Mean'],\n",
    "    fancybox=True, shadow=True, loc='upper left', fontsize=20)\n",
    "    \n",
    "plt.savefig('figures/targetmodels_boxplot.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure\n",
    "\n",
    "for error in errors:\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_2layer_predictions.csv')\n",
    "\n",
    "err_train = []\n",
    "err_val = []\n",
    "err_test = []\n",
    "\n",
    "err_train2 = []\n",
    "err_val2 = []\n",
    "err_test2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # 1-layer model\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # 2-layer model\n",
    "    train = df2[(df['set']==1) & (df2['track']<41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df2[(df2['set']==1) & (df2['track']>=41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_train, err_val, err_test]\n",
    "errors2 = [err_train2, err_val2, err_test2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,4):\n",
    "    pos1.append(2*i-0.254)\n",
    "    pos2.append(2*i+0.254)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM - 1 and 2 Layer')\n",
    "ax.set_xlabel('Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4,6], labels=['Train', 'Validation', 'Test'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='1 Layer', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='2 Layer', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_1layer_2layer_boxplot.pdf') #save the figure\n",
    "\n",
    "\n",
    "Q1 = np.percentile(err_train, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train), IQR, statistics.mean(err_train), statistics.stdev(err_train)))\n",
    "\n",
    "Q1 = np.percentile(err_val, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val), IQR, statistics.mean(err_val), statistics.stdev(err_val)))\n",
    "     \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cncc_predictions.csv') #read in predictions as dataframe\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "\n",
    "#lists of errors (one list for each EF)\n",
    "err_train = [[],[],[],[],[],[],[]] #training errors\n",
    "err_val = [[],[],[],[],[],[],[]] #validation errors\n",
    "err_test = [[],[],[],[],[],[],[]] #test errors\n",
    "\n",
    "#add errors to lists\n",
    "i=0\n",
    "for ef in efs:\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    i+=1\n",
    "    \n",
    "# positions of boxes\n",
    "pos_train = [] \n",
    "pos_val = []\n",
    "pos_test = []\n",
    "for i in range(1,len(efs)+1):\n",
    "    pos_train.append(2*i-0.5)\n",
    "    pos_val.append(2*i)\n",
    "    pos_test.append(2*i+0.5)\n",
    "\n",
    "#make figure, add title and axis labels\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors by EF Strength')\n",
    "ax.set_xlabel('EF Strength')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "\n",
    "# colors for the plot\n",
    "train_c = 'red' #training box colors\n",
    "val_c = 'blue' #validation box colors\n",
    "test_c = 'purple' #test box colors\n",
    "med_c = 'black' #color of median line\n",
    "mean_c = 'green' #color of mean triangle (in legend)\n",
    "\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "# plot training error boxes\n",
    "ax.boxplot(err_train, positions=pos_train, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=train_c, color=train_c),\n",
    "            whiskerprops=dict(color=train_c),\n",
    "            capprops=dict(color=train_c),\n",
    "            medianprops=dict(color=med_c))\n",
    "# plot validation error boxes\n",
    "ax.boxplot(err_val, positions=pos_val, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=val_c, color=val_c),\n",
    "            whiskerprops=dict(color=val_c),\n",
    "            capprops=dict(color=val_c),\n",
    "            medianprops=dict(color=med_c))\n",
    "# plot test error boxes\n",
    "ax.boxplot(err_test, positions=pos_test, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=test_c, color=test_c),\n",
    "            capprops=dict(color=test_c),\n",
    "            whiskerprops=dict(color=test_c),\n",
    "          medianprops=dict(color=med_c))\n",
    "\n",
    "plt.xticks(pos_val,labels=[str(ef)+'mV/mm' for ef in efs]) # labels for xticks \n",
    "\n",
    "# legend information\n",
    "trainplot = plt.plot([], [],'s', label='TRAINING DATA', color=train_c)\n",
    "valplot = plt.plot([], [],'s', label='VALIDATION DATA', color=val_c)\n",
    "testplot = plt.plot([], [],'s', label='TEST DATA', color=test_c)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=med_c)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=mean_c)\n",
    "\n",
    "ax.legend() # create the legen\n",
    "\n",
    "plt.savefig('figures/cncc_by_ef.pdf') #save the figure\n",
    "\n",
    "# print out some statistics\n",
    "for i in range(len(efs)):\n",
    "    error = err_train[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Training Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "        \n",
    "    error = err_val[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Validation Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "        \n",
    "    error = err_test[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "    \n",
    "#print out covariance matrix and pearson's r \n",
    "covariance = np.cov(df[(df['set']==2) & (df['pred_dir'].notna())]['ef'], df[(df['set']==2) & (df['pred_dir'].notna())]['pred_error'].abs())\n",
    "corr, _ = pearsonr(df[(df['set']==2) & (df['pred_dir'].notna())]['ef'], df[(df['set']==2) & (df['pred_dir'].notna())]['pred_error'].abs())\n",
    "print('Covariance Matrix:')\n",
    "print(covariance)\n",
    "print(\"Pearson's r:\")\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no3075.csv')\n",
    "\n",
    "err_train = []\n",
    "err_val = []\n",
    "err_test = []\n",
    "\n",
    "err_train2 = []\n",
    "err_val2 = []\n",
    "err_test2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # 1-layer model\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # 2-layer model\n",
    "    train = df2[(df['set']==1) & (df2['track']<41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df2[(df2['set']==1) & (df2['track']>=41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_train, err_val, err_test]\n",
    "errors2 = [err_train2, err_val2, err_test2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,4):\n",
    "    pos1.append(2*i-0.254)\n",
    "    pos2.append(2*i+0.254)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM - 1 and 2 Layer')\n",
    "ax.set_xlabel('Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4,6], labels=['Train', 'Validation', 'Test'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='Trained on Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm or 75mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_boxplot_no3075_trainvaltest.pdf') #save the figure\n",
    "\n",
    "\n",
    "Q1 = np.percentile(err_train, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train), IQR, statistics.mean(err_train), statistics.stdev(err_train)))\n",
    "\n",
    "Q1 = np.percentile(err_val, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val), IQR, statistics.mean(err_val), statistics.stdev(err_val)))\n",
    "     \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))\n",
    "\n",
    "Q1 = np.percentile(err_train2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30,75 Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train2), IQR, statistics.mean(err_train2), statistics.stdev(err_train2)))\n",
    "\n",
    "Q1 = np.percentile(err_val2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30,75 Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val2), IQR, statistics.mean(err_val2), statistics.stdev(err_val2)))\n",
    "     \n",
    "Q1 = np.percentile(err_test2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30,75 Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test2), IQR, statistics.mean(err_test2), statistics.stdev(err_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/cncc_predictions.csv') #read in predictions as dataframe\n",
    "df2 = pd.read_csv('data/cncc_predictions_no3075.csv') #read in predictions as dataframe\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "\n",
    "#lists of errors (one list for each EF)\n",
    "err1 = [[],[],[],[],[],[],[]] #test errors on original model\n",
    "err2 = [[],[],[],[],[],[],[]] #test errors on model trained with limited voltages\n",
    "\n",
    "#add errors to lists\n",
    "i=0\n",
    "for ef in efs:   \n",
    "    test1 = df1[(df1['set']==2) & (df1['pred_dir'].notna())& (df1['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test1[test1['track']==track]['pred_error']\n",
    "        err1[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test2 = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test2[test2['track']==track]['pred_error']\n",
    "        err2[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "# positions of boxes\n",
    "pos1 = [] \n",
    "pos2 = []\n",
    "for i in range(1,len(efs)+1):\n",
    "    pos1.append(2*i-0.25)\n",
    "    pos2.append(2*i+0.25)\n",
    "\n",
    "#make figure, add title and axis labels\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors by EF Strength')\n",
    "ax.set_xlabel('EF Strength')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "\n",
    "# colors for the plot\n",
    "c1 = 'red' #original model box colors\n",
    "c2 = 'blue' #limited voltage box colors\n",
    "med_c = 'black' #color of median line\n",
    "mean_c = 'green' #color of mean triangle (in legend)\n",
    "\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "# plot test error boxes for original model\n",
    "ax.boxplot(err1, positions=pos1, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "          medianprops=dict(color=med_c))\n",
    "# plot test error boxes for limited EF model\n",
    "ax.boxplot(err2, positions=pos2, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "          medianprops=dict(color=med_c))\n",
    "\n",
    "plt.xticks(range(2,16,2),labels=[str(ef)+'mV/mm' for ef in efs]) # labels for xticks \n",
    "\n",
    "# legend information\n",
    "plot1 = plt.plot([], [],'s', label='Trained with Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm or 75mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=med_c)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=mean_c)\n",
    "\n",
    "ax.legend() # create the legen\n",
    "\n",
    "plt.savefig('figures/cncc_by_ef_no3075.pdf') #save the figure\n",
    "\n",
    "# print out some statistics\n",
    "for i in range(len(efs)):\n",
    "    error = err1[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Original Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "    \n",
    "    error = err2[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Limited EF Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no30.csv')\n",
    "\n",
    "err_train = []\n",
    "err_val = []\n",
    "err_test = []\n",
    "\n",
    "err_train2 = []\n",
    "err_val2 = []\n",
    "err_test2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # 1-layer model\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # 2-layer model\n",
    "    train = df2[(df['set']==1) & (df2['track']<41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df2[(df2['set']==1) & (df2['track']>=41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_train, err_val, err_test]\n",
    "errors2 = [err_train2, err_val2, err_test2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,4):\n",
    "    pos1.append(2*i-0.254)\n",
    "    pos2.append(2*i+0.254)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM - 1 and 2 Layer')\n",
    "ax.set_xlabel('Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4,6], labels=['Train', 'Validation', 'Test'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='Trained on Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_boxplot_no3075_trainvaltest.pdf') #save the figure\n",
    "\n",
    "\n",
    "Q1 = np.percentile(err_train, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train), IQR, statistics.mean(err_train), statistics.stdev(err_train)))\n",
    "\n",
    "Q1 = np.percentile(err_val, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val), IQR, statistics.mean(err_val), statistics.stdev(err_val)))\n",
    "     \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))\n",
    "\n",
    "Q1 = np.percentile(err_train2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train2), IQR, statistics.mean(err_train2), statistics.stdev(err_train2)))\n",
    "\n",
    "Q1 = np.percentile(err_val2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val2), IQR, statistics.mean(err_val2), statistics.stdev(err_val2)))\n",
    "     \n",
    "Q1 = np.percentile(err_test2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test2), IQR, statistics.mean(err_test2), statistics.stdev(err_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/cncc_predictions.csv') #read in predictions as dataframe\n",
    "df2 = pd.read_csv('data/cncc_predictions_no30.csv') #read in predictions as dataframe\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "\n",
    "#lists of errors (one list for each EF)\n",
    "err1 = [[],[],[],[],[],[],[]] #test errors on original model\n",
    "err2 = [[],[],[],[],[],[],[]] #test errors on model trained with limited voltages\n",
    "\n",
    "#add errors to lists\n",
    "i=0\n",
    "for ef in efs:   \n",
    "    test1 = df1[(df1['set']==2) & (df1['pred_dir'].notna())& (df1['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test1[test1['track']==track]['pred_error']\n",
    "        err1[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test2 = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test2[test2['track']==track]['pred_error']\n",
    "        err2[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "# positions of boxes\n",
    "pos1 = [] \n",
    "pos2 = []\n",
    "for i in range(1,len(efs)+1):\n",
    "    pos1.append(2*i-0.25)\n",
    "    pos2.append(2*i+0.25)\n",
    "\n",
    "#make figure, add title and axis labels\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors by EF Strength')\n",
    "ax.set_xlabel('EF Strength')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "\n",
    "# colors for the plot\n",
    "c1 = 'red' #original model box colors\n",
    "c2 = 'blue' #limited voltage box colors\n",
    "med_c = 'black' #color of median line\n",
    "mean_c = 'green' #color of mean triangle (in legend)\n",
    "\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "# plot test error boxes for original model\n",
    "ax.boxplot(err1, positions=pos1, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "          medianprops=dict(color=med_c))\n",
    "# plot test error boxes for limited EF model\n",
    "ax.boxplot(err2, positions=pos2, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "          medianprops=dict(color=med_c))\n",
    "\n",
    "plt.xticks(range(2,16,2),labels=[str(ef)+'mV/mm' for ef in efs]) # labels for xticks \n",
    "\n",
    "# legend information\n",
    "plot1 = plt.plot([], [],'s', label='Trained with Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=med_c)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=mean_c)\n",
    "\n",
    "ax.legend() # create the legen\n",
    "\n",
    "plt.savefig('figures/cncc_by_ef_no30.pdf') #save the figure\n",
    "\n",
    "# print out some statistics\n",
    "for i in range(len(efs)):\n",
    "    error = err1[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Original Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "    \n",
    "    error = err2[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Limited EF Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no200.csv')\n",
    "\n",
    "err_train = []\n",
    "err_val = []\n",
    "err_test = []\n",
    "\n",
    "err_train2 = []\n",
    "err_val2 = []\n",
    "err_test2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # 1-layer model\n",
    "    train = df[(df['set']==1) & (df['track']<41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df[(df['set']==1) & (df['track']>=41) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # 2-layer model\n",
    "    train = df2[(df['set']==1) & (df2['track']<41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(1,41):\n",
    "        cell_errors = train[train['track']==track]['pred_error']\n",
    "        err_train2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))  \n",
    "\n",
    "    val = df2[(df2['set']==1) & (df2['track']>=41) & (df2['pred_dir'].notna()) & (df2['ef']==ef)]\n",
    "    for track in range(41,51):\n",
    "        cell_errors = val[val['track']==track]['pred_error']\n",
    "        err_val2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_train, err_val, err_test]\n",
    "errors2 = [err_train2, err_val2, err_test2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,4):\n",
    "    pos1.append(2*i-0.254)\n",
    "    pos2.append(2*i+0.254)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM - 1 and 2 Layer')\n",
    "ax.set_xlabel('Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4,6], labels=['Train', 'Validation', 'Test'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='Trained on Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_boxplot_no3075_trainvaltest.pdf') #save the figure\n",
    "\n",
    "\n",
    "Q1 = np.percentile(err_train, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train), IQR, statistics.mean(err_train), statistics.stdev(err_train)))\n",
    "\n",
    "Q1 = np.percentile(err_val, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val), IQR, statistics.mean(err_val), statistics.stdev(err_val)))\n",
    "     \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))\n",
    "\n",
    "Q1 = np.percentile(err_train2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_train2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Training Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_train2), IQR, statistics.mean(err_train2), statistics.stdev(err_train2)))\n",
    "\n",
    "Q1 = np.percentile(err_val2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_val2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Validation Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_val2), IQR, statistics.mean(err_val2), statistics.stdev(err_val2)))\n",
    "     \n",
    "Q1 = np.percentile(err_test2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test2), IQR, statistics.mean(err_test2), statistics.stdev(err_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/cncc_predictions.csv') #read in predictions as dataframe\n",
    "df2 = pd.read_csv('data/cncc_predictions_no200.csv') #read in predictions as dataframe\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "\n",
    "#lists of errors (one list for each EF)\n",
    "err1 = [[],[],[],[],[],[],[]] #test errors on original model\n",
    "err2 = [[],[],[],[],[],[],[]] #test errors on model trained with limited voltages\n",
    "\n",
    "#add errors to lists\n",
    "i=0\n",
    "for ef in efs:   \n",
    "    test1 = df1[(df1['set']==2) & (df1['pred_dir'].notna())& (df1['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test1[test1['track']==track]['pred_error']\n",
    "        err1[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    test2 = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test2[test2['track']==track]['pred_error']\n",
    "        err2[i].append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "    i+=1\n",
    "    \n",
    "# positions of boxes\n",
    "pos1 = [] \n",
    "pos2 = []\n",
    "for i in range(1,len(efs)+1):\n",
    "    pos1.append(2*i-0.25)\n",
    "    pos2.append(2*i+0.25)\n",
    "\n",
    "#make figure, add title and axis labels\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors by EF Strength')\n",
    "ax.set_xlabel('EF Strength')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "\n",
    "# colors for the plot\n",
    "c1 = 'red' #original model box colors\n",
    "c2 = 'blue' #limited voltage box colors\n",
    "med_c = 'black' #color of median line\n",
    "mean_c = 'green' #color of mean triangle (in legend)\n",
    "\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "# plot test error boxes for original model\n",
    "ax.boxplot(err1, positions=pos1, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "          medianprops=dict(color=med_c))\n",
    "# plot test error boxes for limited EF model\n",
    "ax.boxplot(err2, positions=pos2, showmeans=True, showfliers=False, notch=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "          medianprops=dict(color=med_c))\n",
    "\n",
    "plt.xticks(range(2,16,2),labels=[str(ef)+'mV/mm' for ef in efs]) # labels for xticks \n",
    "\n",
    "# legend information\n",
    "plot1 = plt.plot([], [],'s', label='Trained with Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 200mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=med_c)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=mean_c)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_by_ef_no200.pdf') #save the figure\n",
    "\n",
    "# print out some statistics\n",
    "for i in range(len(efs)):\n",
    "    error = err1[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Original Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))\n",
    "    \n",
    "    error = err2[i]\n",
    "    Q1 = np.percentile(error, 25, interpolation = 'midpoint') \n",
    "    Q3 = np.percentile(error, 75, interpolation = 'midpoint') \n",
    "    IQR = Q3 - Q1 \n",
    "    print('Limited EF Model Test Error for {}mV/mm:'.format(efs[i]))\n",
    "    print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(error), IQR, statistics.mean(error), statistics.stdev(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no30.csv')\n",
    "\n",
    "err_test = []\n",
    "err_new = []\n",
    "\n",
    "err_test2 = []\n",
    "err_new2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # original model\n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # no 30mV/mm model\n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "# original model\n",
    "test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==30)]\n",
    "for track in range(1,51):\n",
    "    cell_errors = test[test['track']==track]['pred_error']\n",
    "    err_new.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "# no 30mV/mm model\n",
    "test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==30)]\n",
    "for track in range(1,51):\n",
    "    cell_errors = test[test['track']==track]['pred_error']\n",
    "    err_new2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_test, err_new]\n",
    "errors2 = [err_test2, err_new2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,3):\n",
    "    pos1.append(2*i-0.252)\n",
    "    pos2.append(2*i+0.252)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM Interpolation')\n",
    "ax.set_xlabel('Test Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4], labels=['Full Test Set', '30mV/mm Instances'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='Trained on Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 30mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_boxplot_interpolation.pdf') #save the figure\n",
    "    \n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))\n",
    "\n",
    "Q1 = np.percentile(err_new, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_new, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error on 30mV/mm:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_new), IQR, statistics.mean(err_new), statistics.stdev(err_new)))\n",
    "\n",
    "Q1 = np.percentile(err_test2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test2), IQR, statistics.mean(err_test2), statistics.stdev(err_test2)))\n",
    "\n",
    "Q1 = np.percentile(err_new2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_new2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 30 Test Error on 30mV/mm:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_new2), IQR, statistics.mean(err_new2), statistics.stdev(err_new2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no30.csv')\n",
    "\n",
    "print(df.head())\n",
    "test = df[df['set']==2]\n",
    "test['pred_error'] = test['pred_error']**2\n",
    "test = test.groupby(['ef','track']).mean()\n",
    "print(test.head())\n",
    "\n",
    "sns.violinplot(y=test['pred_error'], showfliers=False, cut=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_predictions_no200.csv')\n",
    "\n",
    "err_test = []\n",
    "err_new = []\n",
    "\n",
    "err_test2 = []\n",
    "err_new2 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    # original model\n",
    "    test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "    # no 200mV/mm model\n",
    "    test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = test[test['track']==track]['pred_error']\n",
    "        err_test2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "# original model\n",
    "test = df[(df['set']==2) & (df['pred_dir'].notna())& (df['ef']==200)]\n",
    "for track in range(1,51):\n",
    "    cell_errors = test[test['track']==track]['pred_error']\n",
    "    err_new.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "# no 200mV/mm model\n",
    "test = df2[(df2['set']==2) & (df2['pred_dir'].notna())& (df2['ef']==200)]\n",
    "for track in range(1,51):\n",
    "    cell_errors = test[test['track']==track]['pred_error']\n",
    "    err_new2.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "    \n",
    "errors = [err_test, err_new]\n",
    "errors2 = [err_test2, err_new2]\n",
    "\n",
    "pos1 = []\n",
    "pos2 = []\n",
    "for i in range(1,3):\n",
    "    pos1.append(2*i-0.252)\n",
    "    pos2.append(2*i+0.252)\n",
    "    \n",
    "c1 = 'red'\n",
    "c2 = 'blue'\n",
    "cmed = 'black'\n",
    "cmean = 'green'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for CNCC LSTM Extrapolation')\n",
    "ax.set_xlabel('Test Set')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, positions=pos1, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c1, color=c1),\n",
    "            whiskerprops=dict(color=c1),\n",
    "            capprops=dict(color=c1),\n",
    "            medianprops=dict(color=cmed))\n",
    "ax.boxplot(errors2, positions=pos2, showmeans=True, showfliers=False, notch=False, widths=0.5, patch_artist=True,\n",
    "            boxprops=dict(facecolor=c2, color=c2),\n",
    "            whiskerprops=dict(color=c2),\n",
    "            capprops=dict(color=c2),\n",
    "            medianprops=dict(color=cmed))\n",
    "\n",
    "plt.xticks([2,4], labels=['Full Test Set', '200mV/mm Instances'])\n",
    "\n",
    "plot1 = plt.plot([], [],'s', label='Trained on Full Training Set', color=c1)\n",
    "plot2 = plt.plot([], [],'s', label='Trained without 200mV/mm', color=c2)\n",
    "medianplot = plt.plot([], [], label='Median Cell RMSE', color=cmed)\n",
    "meanplot = plt.plot([], [], '^', label='Mean Cell RMSE', color=cmean)\n",
    "\n",
    "ax.legend() # create the legend\n",
    "\n",
    "plt.savefig('figures/cncc_boxplot_extrapolation.pdf') #save the figure\n",
    "\n",
    "\n",
    "Q1 = np.percentile(err_test, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test), IQR, statistics.mean(err_test), statistics.stdev(err_test)))\n",
    "\n",
    "Q1 = np.percentile(err_new, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_new, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original Test Error on 200mV/mm:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_new), IQR, statistics.mean(err_new), statistics.stdev(err_new)))\n",
    "\n",
    "Q1 = np.percentile(err_test2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_test2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 200 Test Error:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_test2), IQR, statistics.mean(err_test2), statistics.stdev(err_test2)))\n",
    "\n",
    "Q1 = np.percentile(err_new2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err_new2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('No 200 Test Error on 200mV/mm:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err_new2), IQR, statistics.mean(err_new2), statistics.stdev(err_new2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/keratocyte_predictions.csv')\n",
    "df3=pd.read_csv('data/keratocyte_transfer_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "efs = df2['ef'].unique() #the list of EFs\n",
    "for ef in efs:\n",
    "    ker = df2[(df2['pred_dir'].notna()) & (df2['ef']==ef) & (df2['track']>=10)]\n",
    "    ker_transfer = df3[(df3['pred_dir'].notna()) & (df3['ef']==ef) & (df2['track']>=10)]\n",
    "    for track in ker['track'].unique():\n",
    "        cell_errors1 = ker[ker['track']==track]['pred_error']\n",
    "        cell_errors2 = ker_transfer[ker_transfer['track']==track]['pred_error']\n",
    "        err2.append(math.sqrt(mean_squared_error(cell_errors1, np.zeros(len(cell_errors1)))))\n",
    "        err3.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    \n",
    "errors = [err1, err2, err3]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for Keratocytes')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,4), labels=['Benchmark', 'Keratocyte Model', 'CNCC to Keratocyte Transfer'])\n",
    "\n",
    "plt.savefig('figures/keratocyte_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Keratocyte:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "     \n",
    "Q1 = np.percentile(err3, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err3, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer Learning:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err3), IQR, statistics.mean(err3), statistics.stdev(err3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/NHK0001_predictions.csv')\n",
    "df3=pd.read_csv('data/NHK0001_transfer_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "efs = df2['ef'].unique() #the list of EFs\n",
    "for ef in efs:\n",
    "    ker = df2[(df2['pred_dir'].notna()) & (df2['ef']==ef) & (df2['track']>=5)]\n",
    "    ker_transfer = df3[(df3['pred_dir'].notna()) & (df3['ef']==ef) & (df2['track']>=5)]\n",
    "    for track in ker['track'].unique():\n",
    "        cell_errors1 = ker[ker['track']==track]['pred_error']\n",
    "        cell_errors2 = ker_transfer[ker_transfer['track']==track]['pred_error']\n",
    "        err2.append(math.sqrt(mean_squared_error(cell_errors1, np.zeros(len(cell_errors1)))))\n",
    "        err3.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    \n",
    "errors = [err1, err2, err3]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for NHK0001 Keratinocytes')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,4), labels=['Benchmark', 'Keratinocyte Model', 'CNCC to Keratinocyte Transfer'])\n",
    "\n",
    "plt.savefig('figures/NHK0001_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('NHK0001:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "     \n",
    "Q1 = np.percentile(err3, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err3, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err3), IQR, statistics.mean(err3), statistics.stdev(err3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/NHK0002_predictions.csv')\n",
    "df3=pd.read_csv('data/NHK0002_transfer_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "efs = df2['ef'].unique() #the list of EFs\n",
    "for ef in efs:\n",
    "    ker = df2[(df2['pred_dir'].notna()) & (df2['ef']==ef) & (df2['track']>=5)]\n",
    "    ker_transfer = df3[(df3['pred_dir'].notna()) & (df3['ef']==ef) & (df2['track']>=5)]\n",
    "    for track in ker['track'].unique():\n",
    "        cell_errors1 = ker[ker['track']==track]['pred_error']\n",
    "        cell_errors2 = ker_transfer[ker_transfer['track']==track]['pred_error']\n",
    "        err2.append(math.sqrt(mean_squared_error(cell_errors1, np.zeros(len(cell_errors1)))))\n",
    "        err3.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    \n",
    "errors = [err1, err2, err3]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for NHK0002 Keratinocytes')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,4), labels=['Benchmark', 'Keratinocyte Model', 'CNCC to Keratinocyte Transfer'])\n",
    "\n",
    "plt.savefig('figures/NHK0002_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('NHK0002:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "     \n",
    "Q1 = np.percentile(err3, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err3, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err3), IQR, statistics.mean(err3), statistics.stdev(err3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/NHK0802-YL112208_predictions.csv')\n",
    "df3=pd.read_csv('data/NHK0802-YL112208_transfer_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "        \n",
    "efs = df2['ef'].unique() #the list of EFs\n",
    "for ef in efs:\n",
    "    ker = df2[(df2['pred_dir'].notna()) & (df2['ef']==ef) & (df2['track']>=10)]\n",
    "    ker_transfer = df3[(df3['pred_dir'].notna()) & (df3['ef']==ef) & (df2['track']>=10)]\n",
    "    for track in ker['track'].unique():\n",
    "        cell_errors1 = ker[ker['track']==track]['pred_error']\n",
    "        cell_errors2 = ker_transfer[ker_transfer['track']==track]['pred_error']\n",
    "        err2.append(math.sqrt(mean_squared_error(cell_errors1, np.zeros(len(cell_errors1)))))\n",
    "        err3.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    \n",
    "errors = [err1, err2, err3]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for NHK0802-YL112208 Keratinocytes')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,4), labels=['Benchmark', 'Keratinocyte Model', 'CNCC to Keratinocyte Transfer'])\n",
    "\n",
    "plt.savefig('figures/NHK0802-YL112208_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('NHK0802-YL112208:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "     \n",
    "Q1 = np.percentile(err3, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err3, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err3), IQR, statistics.mean(err3), statistics.stdev(err3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df3=pd.read_csv('data/cncc_reverse_predictions.csv')\n",
    "df4=pd.read_csv('data/cncc_reverse_transfer_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_reverse_benchmark_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "err4 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "\n",
    "cells2 = df2[(df2['pred_dir'].notna()) & (df2['track']>20)]\n",
    "cells3 = df3[(df3['pred_dir'].notna()) & (df3['track']>20)]\n",
    "cells4 = df4[(df4['pred_dir'].notna()) & (df4['track']>20)]\n",
    "for track in range(21,51):\n",
    "    cell_errors2 = cells2[cells2['track']==track]['pred_error']\n",
    "    cell_errors3 = cells3[cells3['track']==track]['pred_error']\n",
    "    cell_errors4 = cells4[cells4['track']==track]['pred_error']\n",
    "    \n",
    "    err2.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    err3.append(math.sqrt(mean_squared_error(cell_errors3, np.zeros(len(cell_errors3)))))\n",
    "    err4.append(math.sqrt(mean_squared_error(cell_errors4, np.zeros(len(cell_errors4)))))\n",
    "    \n",
    "errors = [err1, err2, err3, err4]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for Polarity Reversal Dataset')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,5), labels=['Benchmark', 'Benchmark Model on Reversal Set', 'Reversal Model', 'Original to Reversal Transfer'])\n",
    "\n",
    "plt.savefig('figures/reverse_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('NHK0802-YL112208:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "     \n",
    "Q1 = np.percentile(err3, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err3, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err3), IQR, statistics.mean(err3), statistics.stdev(err3)))\n",
    "\n",
    "Q1 = np.percentile(err4, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err4, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err4), IQR, statistics.mean(err4), statistics.stdev(err4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/cncc_predictions.csv')\n",
    "df2=pd.read_csv('data/cncc_reverse_benchmark_predictions.csv')\n",
    "df3=pd.read_csv('data/cncc_reverse_predictions.csv')\n",
    "df4=pd.read_csv('data/cncc_reverse_transfer_predictions.csv')\n",
    "\n",
    "err1 = []\n",
    "err2 = []\n",
    "err3 = []\n",
    "err4 = []\n",
    "\n",
    "efs = [0,15,30,50,75,100,200] #the list of EFs\n",
    "for ef in efs:\n",
    "    cncc = df[(df['set']==2) & (df['pred_dir'].notna()) & (df['ef']==ef)]\n",
    "    for track in range(1,51):\n",
    "        cell_errors = cncc[cncc['track']==track]['pred_error']\n",
    "        err1.append(math.sqrt(mean_squared_error(cell_errors, np.zeros(17))))\n",
    "\n",
    "cells2 = df2[(df2['pred_dir'].notna()) & (df2['track']>20)]\n",
    "cells3 = df3[(df3['pred_dir'].notna()) & (df3['track']>20)]\n",
    "cells4 = df4[(df4['pred_dir'].notna()) & (df4['track']>20)]\n",
    "for track in range(21,51):\n",
    "    cell_errors2 = cells2[cells2['track']==track]['pred_error']\n",
    "    cell_errors3 = cells3[cells3['track']==track]['pred_error']\n",
    "    cell_errors4 = cells4[cells4['track']==track]['pred_error']\n",
    "    \n",
    "    err2.append(math.sqrt(mean_squared_error(cell_errors2, np.zeros(len(cell_errors2)))))\n",
    "    err3.append(math.sqrt(mean_squared_error(cell_errors3, np.zeros(len(cell_errors3)))))\n",
    "    err4.append(math.sqrt(mean_squared_error(cell_errors4, np.zeros(len(cell_errors4)))))\n",
    "    \n",
    "errors = [err1, err2, err4]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Prediction Errors for Polarity Reversal Dataset')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('RMSE of Individual Cells')\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "ax.boxplot(errors, showmeans=True, showfliers=False)\n",
    "plt.xticks(np.arange(1,len(errors)+1), labels=['Benchmark', 'Benchmark Model on Reversal Set', 'Original to Reversal Transfer'])\n",
    "\n",
    "plt.savefig('figures/reverse_boxplot.pdf') #save the figure\n",
    "\n",
    "Q1 = np.percentile(err1, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err1, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Benchmark:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err1), IQR, statistics.mean(err1), statistics.stdev(err1)))\n",
    "\n",
    "Q1 = np.percentile(err2, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err2, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Original on Reverse:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err2), IQR, statistics.mean(err2), statistics.stdev(err2)))\n",
    "\n",
    "Q1 = np.percentile(err4, 25, interpolation = 'midpoint') \n",
    "Q3 = np.percentile(err4, 75, interpolation = 'midpoint') \n",
    "IQR = Q3 - Q1 \n",
    "print('Transfer on Reverse:')\n",
    "print('median: {}, IQR: {}, mean: {}, standard deviation: {}'.format(statistics.median(err4), IQR, statistics.mean(err4), statistics.stdev(err4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cncc_predictions.csv')\n",
    "test = df[(df['set']==2)]\n",
    "\n",
    "efs = [0,15,30,50,75,100,200]\n",
    "#efs = [50]\n",
    "#plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.viridis(np.linspace(0,1,len(efs))))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "fig.set_dpi(400)\n",
    "#for i in range(len(efs)):\n",
    "    #ax.plot([0,1], [i, 2*i])\n",
    "\n",
    "max_avs = {}\n",
    "mean_avs = {}\n",
    "min_avs = {}\n",
    "\n",
    "act_means = {}\n",
    "act_stds = {}\n",
    "for ef in efs:\n",
    "    this_ef = test[test['ef']==ef]\n",
    "    max_av = [] #max model-average dir prediction for each slice of this EF\n",
    "    mean_av = [] #mean model-average dir prediction for each slice of this EF\n",
    "    min_av = [] #min model-average dir prediction for each slice of this EF\n",
    "    \n",
    "    act_mean = [] #mean true dir value for each slice of this EF\n",
    "    act_std = [] #std dev of mean true dir value for each slice of this EF\n",
    "    \n",
    "    for sl in range(21,38): #loop through slices where predictions are made\n",
    "        this_slice = this_ef[this_ef['slice']==sl]\n",
    "        \n",
    "        act_mean.append(statistics.mean(this_slice['cum_dir']))\n",
    "        act_std.append(statistics.stdev(this_slice['cum_dir']))\n",
    "        \n",
    "        all_avs = [] #list of the average predicted directedness for this ef+slice for each model\n",
    "        for i in range(50): #loop through the 50 models\n",
    "            this_model = this_slice['pred_dir{}'.format(i)].dropna()\n",
    "            all_avs.append(statistics.mean(this_model))\n",
    "        \n",
    "        max_av.append(max(all_avs))\n",
    "        mean_av.append(statistics.mean(all_avs))\n",
    "        min_av.append(min(all_avs))\n",
    "        \n",
    "    max_avs[ef] = max_av\n",
    "    mean_avs[ef] = mean_av\n",
    "    min_avs[ef] = min_av\n",
    "    act_means[ef] = act_mean\n",
    "    act_stds[ef] = act_std\n",
    "    \n",
    "colors = ['#1e14de','#1873db','#2be3e0','#25c460','#ede72b','#ebba28','#db3627']\n",
    "\n",
    "lines = []\n",
    "shades = []\n",
    "for i in range(len(efs)):\n",
    "    ef = efs[i]\n",
    "    #max_plot = plt.plot(range(21,38),max_avs[ef], color='k')\n",
    "    #line, = plt.plot(range(21,38),mean_avs[ef], color=colors[i])\n",
    "    line, = plt.plot(range(21,38),mean_avs[ef], color='k')\n",
    "    lines.append(line)\n",
    "    #min_plot = plt.plot(range(21,38),min_avs[ef], color='k')\n",
    "    shade = plt.fill_between(range(21,38),min_avs[ef],max_avs[ef], color=colors[i], alpha=0.3)\n",
    "    shades.append(shade)\n",
    "    \n",
    "    #plt.plot(range(21,38),act_means[ef], color=colors[i], linestyle='--') #actual mean\n",
    "    plt.plot(range(21,38),act_means[ef], color='k', linestyle='--') #actual mean\n",
    "\n",
    "#example lines to use for legend\n",
    "ex_pred, = plt.plot([],color='k')\n",
    "ex_true, = plt.plot([],color='k',linestyle='--')\n",
    "    \n",
    "lgd = ax.legend(shades + [ex_pred,ex_true],\n",
    "          ['{}mV/mm'.format(ef) for ef in efs] + ['Mean Prediction','Mean Ground Truth'],\n",
    "         bbox_to_anchor=(.97,.97), fancybox=True, shadow=True, loc='upper left', fontsize=22)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "ax.set_xlabel('Timestep',fontsize=28)\n",
    "ax.set_ylabel('Directedness',fontsize=28)\n",
    "ax.set_title('Average Ground Truth vs Predicted Directedness By Timestep',fontsize=32)\n",
    "        \n",
    "#plt.show()\n",
    "fig.savefig('figures/1step_pred_confidence.pdf',bbox_extra_artists=(lgd,),bbox_inches='tight') #save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cncc_predictions.csv')\n",
    "test = df[(df['set']==2) & (df['ef']==50)]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(14, 8) # set figure size\n",
    "\n",
    "for track in range(1,51):\n",
    "    cell = test[test['track']==track]\n",
    "    plt.plot(range(1,38),cell['cum_dir'], 'b')\n",
    "\n",
    "avgs = []\n",
    "for sl in range(1,38):\n",
    "    dirs = test[test['slice']==sl]\n",
    "    avgs.append(statistics.mean(dirs['cum_dir']))\n",
    "    \n",
    "plt.plot(range(1,38),avgs,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directedness Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cncc.csv')\n",
    "\n",
    "ef = 200\n",
    "setnum = 2\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for track in range(1,51):\n",
    "    cell = df.loc[(df['ef']==ef) & (df['set']==setnum) & (df['track']==track)]\n",
    "    ax.plot(cell['slice']-1,cell['cum_dir'])\n",
    "\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlim([-.1, 36])\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('Time', fontsize=20)\n",
    "\n",
    "ax.set_yticks([-1,0,1])\n",
    "ax.set_yticklabels([-1,0,1], fontsize=20)\n",
    "ax.set_ylabel('Directedness', fontsize=20)\n",
    "\n",
    "fig.savefig('dir_over_time_200mVmm_set2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cncc.csv')\n",
    "\n",
    "ef = 200\n",
    "setnum = 2\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "for track in range(1,51):\n",
    "    cell = df.loc[(df['ef']==ef) & (df['set']==setnum) & (df['track']==track)]\n",
    "    ax.plot(cell['x'],cell['y'])\n",
    "    \n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_xticklabels([])\n",
    "\n",
    "ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "\n",
    "fig.savefig('groundtruth_200mVmm_set2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr=pd.read_csv('data/cncc_reverse.csv')\n",
    "df_left = dfr.loc[dfr['set']=='left']\n",
    "df_right = dfr.loc[dfr['set']=='right']\n",
    "\n",
    "dfr.head()\n",
    "\n",
    "for i in range(1, int(max(df_right['track'])+1)):\n",
    "    max_slice = max(df_left['slice'])\n",
    "\n",
    "    last_x = df_left.loc[(df_left['track']==i)&(df_left['slice']==max_slice), 'x'].to_numpy()[0]\n",
    "    last_y = df_left.loc[(df_left['track']==i)&(df_left['slice']==max_slice), 'y'].to_numpy()[0]\n",
    "\n",
    "    dfr.loc[(dfr['track']==i)&(dfr['slice']==1)&(dfr['set']=='right'), 'x2'] = last_x\n",
    "    dfr.loc[(dfr['track']==i)&(dfr['slice']==1)&(dfr['set']=='right'), 'y2'] = last_y\n",
    "\n",
    "    for j in range(2, int(max(dfr['slice'])+1)):\n",
    "        deltax = dfr.loc[(dfr['track']==i)&(dfr['slice']==j)&(dfr['set']=='right'), 'x'].to_numpy()[0] - dfr.loc[(dfr['track']==i)&(dfr['slice']==j-1)&(dfr['set']=='right'), 'x'].to_numpy()[0]\n",
    "        prevx = dfr.loc[(dfr['track']==i)&(dfr['slice']==j-1)&(dfr['set']=='right'), 'x2'].to_numpy()[0]\n",
    "        deltay = dfr.loc[(dfr['track']==i)&(dfr['slice']==j)&(dfr['set']=='right'), 'y'].to_numpy()[0] - dfr.loc[(dfr['track']==i)&(dfr['slice']==j-1)&(dfr['set']=='right'), 'y'].to_numpy()[0]\n",
    "        prevy = dfr.loc[(dfr['track']==i)&(dfr['slice']==j-1)&(dfr['set']=='right'), 'y2'].to_numpy()[0]\n",
    "\n",
    "        dfr.loc[(dfr['track']==i)&(dfr['slice']==j)&(dfr['set']=='right'), 'x2'] = prevx + deltax\n",
    "        dfr.loc[(dfr['track']==i)&(dfr['slice']==j)&(dfr['set']=='right'), 'y2'] = prevy + deltay\n",
    "\n",
    "dfr['dir2'] = dfr['x2']/np.sqrt(dfr['x2']**2 + dfr['y2']**2)\n",
    "\n",
    "dfr = dfr[dfr['slice'] != 25]\n",
    "dfr.loc[dfr['set']=='right','x'] = dfr.loc[dfr['set']=='right','x2']\n",
    "dfr.loc[dfr['set']=='right','y'] = dfr.loc[dfr['set']=='right','y2']\n",
    "dfr.loc[dfr['set']=='right','cum_dir'] = dfr.loc[dfr['set']=='right','dir2']\n",
    "dfr.loc[dfr['set']=='right','slice'] = dfr.loc[dfr['set']=='right','slice'] + 24\n",
    "dfr.loc[dfr['set']=='right','ef'] = -dfr.loc[dfr['set']=='right','ef']\n",
    "dfr['volt'] = dfr['ef'] / 1000\n",
    "dfr['ef'] = dfr['ef'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in dfr['track'].unique():\n",
    "    plt.plot(dfr.loc[dfr['track']==track, 'slice'], dfr.loc[dfr['track']==track,'cum_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8),dpi=180)\n",
    "plt.errorbar(dfr['slice'].unique(),dfr.groupby(['slice']).mean()['cum_dir'],\n",
    "            yerr = dfr.groupby(['slice']).sem()['cum_dir'])\n",
    "plt.title('Polarity Reversal Directedness',fontsize=28)\n",
    "plt.xticks([0,10,20,30,40,49],fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel('Timestep',fontsize=24)\n",
    "plt.ylabel('Directedness',fontsize=24)\n",
    "\n",
    "fig.savefig('figures/reversal_averagedir.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
